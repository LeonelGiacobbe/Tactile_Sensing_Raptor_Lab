V1 used 9000 wood images. 9000 hard rubber images,
3000 gel, 3000 soft foam, and 3000 no-contact data.
27,000 images in total
learning rate was 1e-4
dropout_p was 0.15
batch size was 256
I reduced nStep from 20 to 15 in training, back to what it was in single-agent case
Main difference to v2 is the fact that I think there was an issue with the way states
were split for prediction in mpc layer. Testing if my hypothesis is right here
------------------------------------------------------------------------------------
Test set (2700 samples): Average OG loss: 62.6754

Agent 1 OG loss:  23.980032205581665
Agent 2 OG loss:  38.82009935379028
Train Epoch: 1 [256/10800 (5%)]	Loss: 62.800133
Agent 1 OG loss:  25.345677375793457
Agent 2 OG loss:  36.96368670463562
Train Epoch: 1 [512/10800 (7%)]	Loss: 62.309364
Agent 1 OG loss:  21.423269271850586
Agent 2 OG loss:  36.208223819732666
Train Epoch: 1 [768/10800 (9%)]	Loss: 57.631493
Agent 1 OG loss:  28.32279634475708
Agent 2 OG loss:  35.667567014694214
Train Epoch: 1 [1024/10800 (12%)]	Loss: 63.990364
Agent 1 OG loss:  24.367157220840454
Agent 2 OG loss:  40.1412410736084
Train Epoch: 1 [1280/10800 (14%)]	Loss: 64.508400
Agent 1 OG loss:  23.791666507720947
Agent 2 OG loss:  35.26814913749695
Train Epoch: 1 [1536/10800 (16%)]	Loss: 59.059814
Agent 1 OG loss:  24.055700302124023
Agent 2 OG loss:  36.95937919616699
Train Epoch: 1 [1792/10800 (19%)]	Loss: 61.015079
Agent 1 OG loss:  25.562506675720215
Agent 2 OG loss:  37.45276737213135
Train Epoch: 1 [2048/10800 (21%)]	Loss: 63.015274
Agent 1 OG loss:  21.529626607894897
Agent 2 OG loss:  38.22866463661194
------------------------------------------------------------------------------------
Test set (2700 samples): Average OG loss: 19.9982

Agent 1 OG loss:  1.6475191414356232
Agent 2 OG loss:  2.0999661087989807
Train Epoch: 51 [256/10800 (5%)]	Loss: 3.747485
Agent 1 OG loss:  1.511193335056305
Agent 2 OG loss:  1.720132052898407
Train Epoch: 51 [512/10800 (7%)]	Loss: 3.231325
Agent 1 OG loss:  1.4821837246418
Agent 2 OG loss:  2.4589826464653015
Train Epoch: 51 [768/10800 (9%)]	Loss: 3.941166
Agent 1 OG loss:  1.4283309876918793
Agent 2 OG loss:  1.899464726448059
Train Epoch: 51 [1024/10800 (12%)]	Loss: 3.327796
Agent 1 OG loss:  1.4493972957134247
Agent 2 OG loss:  2.124598205089569
Train Epoch: 51 [1280/10800 (14%)]	Loss: 3.573995
Agent 1 OG loss:  1.284601479768753
Agent 2 OG loss:  1.5349082350730896
Train Epoch: 51 [1536/10800 (16%)]	Loss: 2.819510
Agent 1 OG loss:  1.2388890385627747
Agent 2 OG loss:  2.108411431312561
Train Epoch: 51 [1792/10800 (19%)]	Loss: 3.347301
Agent 1 OG loss:  1.404714971780777
Agent 2 OG loss:  1.9197419881820679
Train Epoch: 51 [2048/10800 (21%)]	Loss: 3.324457
Agent 1 OG loss:  1.4205418825149536
Agent 2 OG loss:  2.730503499507904
