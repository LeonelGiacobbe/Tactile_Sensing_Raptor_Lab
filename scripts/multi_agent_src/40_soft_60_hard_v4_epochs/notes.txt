Diff to previous version is the use of two different encoders for the two agents, and changing
"/3" to "/2" in read_empty_data. It should increase the velocity of the grippers while closing
Also, ResNet backbone was not frozen. According to author of single-agent paper, this could help
learn features better.
del_t was also changed to 1/10 since we'll be running the model at 10hz
------------------------------------------------------------------------------------
Test set (5430 samples): Average loss: 72.9917

Agent 1 loss:  35.568737745285034
Agent 2 loss:  38.36513829231262
Train Epoch: 1 [256/21720 (2%)]	Loss: 73.933876
Agent 1 loss:  37.81907844543457
Agent 2 loss:  39.82341694831848
Train Epoch: 1 [512/21720 (4%)]	Loss: 77.642494
Agent 1 loss:  34.91496968269348
Agent 2 loss:  40.85757637023926
Train Epoch: 1 [768/21720 (5%)]	Loss: 75.772545
Agent 1 loss:  36.81845998764038
Agent 2 loss:  39.19502568244934
Train Epoch: 1 [1024/21720 (6%)]	Loss: 76.013489
Agent 1 loss:  35.61716961860657
Agent 2 loss:  32.72975516319275
Train Epoch: 1 [1280/21720 (7%)]	Loss: 68.346924
Agent 1 loss:  37.194993019104004
Agent 2 loss:  35.02661991119385
Train Epoch: 1 [1536/21720 (8%)]	Loss: 72.221619
Agent 1 loss:  31.245322465896606
Agent 2 loss:  39.16863465309143
Train Epoch: 1 [1792/21720 (9%)]	Loss: 70.413956
Agent 1 loss:  39.9492564201355
Agent 2 loss:  37.323874950408936
------------------------------------------------------------------------------------
Test set (5430 samples): Average OG loss: 16.8340

Agent 1 loss:  1.5925305485725403
Agent 2 loss:  2.113398104906082
Train Epoch: 49 [256/21720 (2%)]	Loss: 3.705929
Agent 1 loss:  1.8565721809864044
Agent 2 loss:  2.0655291974544525
Train Epoch: 49 [512/21720 (4%)]	Loss: 3.922101
Agent 1 loss:  1.8156333267688751
Agent 2 loss:  1.9689765870571136
Train Epoch: 49 [768/21720 (5%)]	Loss: 3.784610
Agent 1 loss:  2.167370855808258
Agent 2 loss:  2.2044939398765564
Train Epoch: 49 [1024/21720 (6%)]	Loss: 4.371865
Agent 1 loss:  2.044541358947754
Agent 2 loss:  2.3687872886657715
Train Epoch: 49 [1280/21720 (7%)]	Loss: 4.413329
Agent 1 loss:  1.739757388830185
Agent 2 loss:  1.886771321296692
Train Epoch: 49 [1536/21720 (8%)]	Loss: 3.626529
Agent 1 loss:  2.3729438483715057
Agent 2 loss:  2.506928265094757
Train Epoch: 49 [1792/21720 (9%)]	Loss: 4.879872
Agent 1 loss:  2.015539824962616
Agent 2 loss:  1.9433882236480713
