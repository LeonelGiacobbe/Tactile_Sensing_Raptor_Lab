This combines the alternating and two loops dataset
Approximately 15,000 wood, 15,000 rubber
6,600 foam, 6,600 gel, 6,600 empty
learning rate was 1e-4
dropout_p was 0.15
batch size was 256
nStep is 15
Diff to previous version is now using learned param for scaling in q_coupling. Before, we were
using 0.25 (arbitrary value, never broke). Next step is to test assymetry in other_effect_batch
Up to 30 was trained on 1e-4, plateau scheduler was used thereafter
------------------------------------------------------------------------------------
Test set (5430 samples): Average loss: 73.0091

Agent 1 loss:  36.44244694709778
Agent 2 loss:  35.2419376373291
Train Epoch: 1 [256/21720 (2%)]	Loss: 71.684387
Agent 1 loss:  30.377568244934082
Agent 2 loss:  39.171090841293335
Train Epoch: 1 [512/21720 (4%)]	Loss: 69.548660
Agent 1 loss:  38.48403573036194
Agent 2 loss:  37.87531042098999
Train Epoch: 1 [768/21720 (5%)]	Loss: 76.359344
Agent 1 loss:  32.12260150909424
Agent 2 loss:  35.73047685623169
Train Epoch: 1 [1024/21720 (6%)]	Loss: 67.853073
Agent 1 loss:  35.06495809555054
Agent 2 loss:  36.96538972854614
Train Epoch: 1 [1280/21720 (7%)]	Loss: 72.030350
Agent 1 loss:  36.00172448158264
Agent 2 loss:  36.025739908218384
Train Epoch: 1 [1536/21720 (8%)]	Loss: 72.027466
Agent 1 loss:  35.702717542648315
Agent 2 loss:  33.323469161987305
------------------------------------------------------------------------------------
Test set (5430 samples): Average OG loss: 16.8340

Agent 1 loss:  1.5925305485725403
Agent 2 loss:  2.113398104906082
Train Epoch: 49 [256/21720 (2%)]	Loss: 3.705929
Agent 1 loss:  1.8565721809864044
Agent 2 loss:  2.0655291974544525
Train Epoch: 49 [512/21720 (4%)]	Loss: 3.922101
Agent 1 loss:  1.8156333267688751
Agent 2 loss:  1.9689765870571136
Train Epoch: 49 [768/21720 (5%)]	Loss: 3.784610
Agent 1 loss:  2.167370855808258
Agent 2 loss:  2.2044939398765564
Train Epoch: 49 [1024/21720 (6%)]	Loss: 4.371865
Agent 1 loss:  2.044541358947754
Agent 2 loss:  2.3687872886657715
Train Epoch: 49 [1280/21720 (7%)]	Loss: 4.413329
Agent 1 loss:  1.739757388830185
Agent 2 loss:  1.886771321296692
Train Epoch: 49 [1536/21720 (8%)]	Loss: 3.626529
Agent 1 loss:  2.3729438483715057
Agent 2 loss:  2.506928265094757
Train Epoch: 49 [1792/21720 (9%)]	Loss: 4.879872
Agent 1 loss:  2.015539824962616
Agent 2 loss:  1.9433882236480713
